{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка данных и их подготовка к анализу и подаче в модель.\n",
    "\n",
    "Под предобработкой понимаются следующие этапы работы с данными:\n",
    "\n",
    "очистка данных от аномальных значений (выбросов);\n",
    "работа с пропущенными значениями;\n",
    "удаление признаков, которые не несут полезной информации;\n",
    "создание новых признаков;\n",
    "преобразование признаков и приведение данных к необходимому для анализа и модели формату.\n",
    "Этап подготовки данных является самым трудоёмким и времязатратным при работе с любой бизнес-задачей. В среднем он занимает около 60-70% общей работы специалиста!\n",
    "\n",
    "Почему этот этап так важен?\n",
    "\n",
    "Ответ на этот вопрос кроется в распространённой среди специалистов поговорке «Мусор на входе — мусор на выходе», что означает следующее: если данные плохо подготовлены, то и результат прогнозирования даже самой мощной в мире нейронной сети будет сильно разниться с действительностью.\n",
    "\n",
    "FEATURE ENGINEERING\n",
    "\n",
    "Одним из этапов подготовки данных является удаление, преобразование и создание столбцов таблицы.\n",
    "\n",
    "Зачем нужны такие манипуляции? \n",
    "\n",
    "Оказывается, что при правильных преобразованиях таблицы можно добиваться лучшего качества прогноза, а также извлекать новую информацию из данных и интерпретировать её для заказчика. \n",
    "\n",
    "Такой подход часто называют Feature Engineering, или генерацией признаков (фичей).\n",
    "\n",
    "→ На самом деле, в этом термине заложен более глубокий смысл, ведь Feature Engineering — это целая методология получения более качественных и более производительных моделей за счёт манипуляций над данными. Специалисты часто называют данную методологию настоящим искусством, которое может быть освоено лишь с годами практики решения задач, ведь необходимо быть экспертом в исследуемой предметной области, чтобы понимать, как признаки влияют друг на друга и какое преобразование стоит к ним применить. \n",
    "\n",
    "\n",
    "На протяжении всего модуля мы будем производить множество тренировочных преобразований с нашей таблицей. Поэтому, чтобы не переопределять переменную melb_data и тем самым не повредить первоначальный DataFrame, создадим копию melb_df с помощью метода copy():\n",
    "\n",
    "melb_df = melb_data.copy()\n",
    "melb_df.head()\n",
    "\n",
    "Лайфхак. Старайтесь всегда оставлять переменную с первоначальным DataFrame неизменной, создавайте копию исходной таблицы и совершайте преобразования на ней. Это оградит вас от ошибок, которые можно совершить при подготовке данных. Например, если вы понимаете, что преобразование оказалось неудачным, достаточно будет лишь запустить ячейку, в которой вы производите копирование, а не читать таблицу заново. Особенно критичным это может быть, когда количество строк в таблице исчисляется миллионами и её чтение занимает до нескольких минут.\n",
    "\n",
    "УДАЛЕНИЕ СТОЛБЦОВ\n",
    "\n",
    "→ Среди списка базовых операций над столбцами в Pandas важное место занимает возможность удаления столбцов из таблицы. Это может быть полезно, например, когда в данных есть признаки, которые не несут полезной информации.\n",
    "\n",
    "Представим, что мы хотим построить модель, которая бы предсказывала цену объекта недвижимости в Мельбурне. Даже не будучи профессиональными риелторами, мы можем легко сделать следующие выводы:\n",
    "\n",
    "цена объекта никак не зависит от его порядкового номера (столбец index);\n",
    "признак, описывающий долготу и широту в виде кортежа Coordinates, дублирует информацию, представленную в столбцах Longitude и Lattitude.\n",
    "За удаление строк и столбцов в таблице отвечает метод drop().\n",
    "\n",
    "Основные параметры метода drop()\n",
    "\n",
    "labels — порядковые номера или имена столбцов, которые подлежат удалению; если их несколько, то передаётся список;\n",
    "axis — ось совершения операции, axis=0 — удаляются строки, axis=1 — удаляются столбцы;\n",
    "inplace — если параметр выставлен на True, происходит замена изначального DataFrame на новый, при этом метод ничего не возвращает; если на False — возвращается копия DataFrame, из которой удалены указанные строки (столбцы), при этом первоначальный DataFrame не изменяется; по умолчанию параметр равен False.\n",
    "\n",
    "Удалим столбцы index и Coordinates из таблицы с помощью метода drop(). Выведем первые пять строк таблицы и убедимся, что всё прошло успешно.\n",
    "\n",
    "melb_df = melb_df.drop(['index', 'Coordinates'], axis=1)\n",
    "melb_df.head()\n",
    "Альтернативный вариант:\n",
    "\n",
    "melb_df.drop(['index','Coordinates'],axis=1,inplace=True)\n",
    "melb_df.head()\n",
    "\n",
    "МАТЕМАТИЧЕСКИЕ ОПЕРАЦИИ СО СТОЛБЦАМИ\n",
    "\n",
    "→ Pandas поддерживает базовые математические операции между столбцами: столбцы можно складывать, вычитать, умножать, делить между собой, а также возводить в степень. С помощью таких операций мы можем создавать новые признаки или производить преобразования над старыми.\n",
    "\n",
    "Причём все операции со столбцами совершаются поэлементно, очень быстро, а самое главное — без написания циклов.\n",
    "\n",
    "Такая производительность достигается за счёт того, что все математические операции со столбцами выполняются на языке программирования С, что значительно повышает скорость вычислений по сравнению с перебором элементов в цикле. \n",
    "\n",
    "Например, давайте создадим переменную total_rooms, в которой будем хранить общее количество комнат в здании. Для этого выполним сложение столбцов с количеством комнат, ванн и спален:\n",
    "\n",
    "total_rooms = melb_df['Rooms'] + melb_df['Bedroom'] + melb_df['Bathroom']\n",
    "display(total_rooms)\n",
    "\n",
    "А теперь введём признак MeanRoomsArea, который соответствует средней площади одной комнаты для каждого объекта. Для этого разделим площадь здания на полученное ранее общее количество комнат:\n",
    "\n",
    "melb_df['MeanRoomsArea'] = melb_df['BuildingArea'] / total_rooms\n",
    "display(melb_df['MeanRoomsArea'])\n",
    "\n",
    "Можно ввести ещё один интересный признак — AreaRatio, коэффициент соотношения площади здания (BuildingArea) и площади участка (Landsize). Для этого разницу двух площадей поделим на их сумму:\n",
    "\n",
    "diff_area = melb_df['BuildingArea'] - melb_df['Landsize']\n",
    "sum_area = melb_df['BuildingArea'] + melb_df['Landsize']\n",
    "melb_df['AreaRatio'] = diff_area/sum_area\n",
    "display(melb_df['AreaRatio'])\n",
    "\n",
    "Что показывает такой коэффициент? Если присмотреться, можно увидеть, что AreaRatio лежит в интервале от -1 до 1.\n",
    "\n",
    "Рассмотрим три случая, чтобы понять его значение:\n",
    "\n",
    "Если рассматриваемые площади равны, то числитель дроби зануляется и коэффициент тоже равен 0.\n",
    "Если одна из площадей начинает доминировать над другой, то коэффициент начинает расти в отрицательную сторону, если площадь участка больше площади здания, и в положительную сторону, если наоборот.\n",
    "Наконец, в предельном случае, если площадь здания равна 0, то числитель дроби равен знаменателю со знаком минус, а коэффициент равен -1, а если площадь участка равна 0, то числитель дроби равен знаменателю со знаком плюс, а коэффициент равен 1.\n",
    "Таким образом, значение в столбце AreaRatio служит своеобразным указателем соотношения площадей объекта недвижимости. Для пустырей — участков без строений — он будет равен -1, для домов без территории — 1, во всех остальных случаях мы можем увидеть, какая площадь больше — здания или участка.\n",
    "\n",
    "\n",
    "ПРИЗНАКИ ДАТЫ И ВРЕМЕНИ\n",
    "\n",
    "→ При генерации новых признаков очень ценным может стать временной признак (признак даты и времени). Это особый тип данных, с которым приходится сталкиваться в большинстве задач по обработке данных. В реальных задачах часто нужно сравнивать даты, выделять день недели или час, вычислять различные интервалы между датами. \n",
    "\n",
    "Например, в наших данных об объектах недвижимости есть признак даты продажи — столбец Date. Из данного признака можно выделить массу полезной информации, например год, месяц или день недели продажи имущества. На рынке недвижимости, как известно, присутствует сезонность: есть периоды, когда недвижимость покупается чаще, а есть интервалы времени, когда рынок претерпевает застой, поэтому было бы неплохо учитывать эту сезонность при анализе рынка.\n",
    "\n",
    "ФОРМАТ DATETIME\n",
    "\n",
    "В жизни мы видим даты в привычных для нас форматах. Например, запись 01.12.18 обычно означает 1 декабря 2018 года. Однако для жителей США эта дата окажется 12 января 2018 года, так как для них привычнее сначала указывать номер месяца, а затем день. \n",
    "\n",
    "Многие выгрузки из систем и баз данных имеют свой служебный формат. Например, формат времени из разных систем может отличаться:\n",
    "\n",
    "2018-11-09 15:45:21;\n",
    "11/09/2018 3:45:20 PM;\n",
    "2018-11-09T15:45:21.2984.\n",
    "Для всех этих случаев необходимо задавать формат распознавания дат и уметь сравнивать их между собой. Для этого был создан единый способ обозначения даты и времени. \n",
    "\n",
    "Таким форматом в Pandas является формат datetime, который записывается как YYYY-MM-DD HH: MM: SS, то есть составляющие времени указываются в следующем порядке: год, месяц, день, час, минута, секунда.\n",
    "\n",
    "В наших данных дата записана в виде DD/MM/YYYY, например 3/12/2017. Посмотрим на это:\n",
    "\n",
    "display(melb_df['Date'])\n",
    "\n",
    "Для того чтобы преобразовывать столбцы с датами, записанными в распространённых форматах, в формат datetime, можно воспользоваться функцией pandas.to_datetime(). В нашем случае в функции нужно указать параметр dayfirst=True, который будет обозначать, что в первоначальном признаке первым идет день. Преобразуем столбец Date в формат datetime, передав его в эту функцию:\n",
    "\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)\n",
    "display(melb_df['Date'])\n",
    "\n",
    "В результате мы переопределяем признак Date в формат datetime. При этом так как в изначальном варианте время не было указано, то и после преобразования оно опускается.\n",
    "\n",
    "Стоит обратить внимание, что изменился тип данных для столбца Date, теперь его тип — datetime64. Рассмотрим несколько возможностей этого типа данных.\n",
    "\n",
    "ВЫДЕЛЕНИЕ АТРИБУТОВ DATETIME\n",
    "\n",
    "Тип данных datetime позволяет с помощью специального аксессора dt выделять составляющие времени из каждого элемента столбца, такие как:\n",
    "\n",
    "date — дата;\n",
    "year, month, day — год, месяц, день;\n",
    "time — время;\n",
    "hour, minute, second — час, минута, секунда;\n",
    "dayofweek — номер дня недели, от 0 до 6, где 0 — понедельник, 6 — воскресенье;\n",
    "day_name — название дня недели;\n",
    "dayofyear — порядковый день года;\n",
    "quarter — квартал (интервал в три месяца).\n",
    "\n",
    "Аксессор — это атрибут столбца, хранящий переменные, которые были строковым представлением времени, а затем были изменены с помощью pd.to_datetime().\n",
    "\n",
    "Обратите внимание, что вы не сможете обратиться к аксессору, если ваш столбец не приведён к типу datetime.\n",
    "\n",
    "Например, обратившись по атрибуту dt.year в столбце Date, мы можем «достать» год продажи и понять, за какой интервал времени (в годах) представлены наши данные, а также на какой год приходится наибольшее число продаж:\n",
    "\n",
    "years_sold = melb_df['Date'].dt.year\n",
    "print(years_sold)\n",
    "print('Min year sold:', years_sold.min())\n",
    "print('Max year sold:', years_sold.max())\n",
    "print('Mode year sold:', years_sold.mode()[0])\n",
    "\n",
    "В результате обращения к атрибуту datetime melb_df['Date'].dt.year мы получаем объект Series, в котором в качестве значений выступают годы продажи объектов недвижимости. Мы можем занести результат в переменную year_sold и далее работать с ней как с обычным столбцом Series — вычислять максимум, минимум и модальное значение.\n",
    "\n",
    "Из результатов видно, что данные представлены за интервал с 2016 по 2017 год и наибольшее количество объектов было продано в 2017 году.\n",
    "\n",
    "Примечание. Так как модальных значений в столбце может быть несколько, метод mode() возвращает объект Series, даже если мода в данных только одна. Чтобы сохранить стилистику вывода информации о годе продажи и выводить только число, а не Series, мы обращаемся к результату работы метода mode() по индексу 0.\n",
    "\n",
    "Теперь попробуем понять, на какие месяцы приходится пик продаж объектов недвижимости. Для этого выделим атрибут dt.month и на этот раз занесём результат в столбец MonthSale, а затем найдём относительную частоту продаж для каждого месяца от общего количества продаж — для этого используем метод value_counts() с параметром normalize (вывод в долях):\n",
    "\n",
    "melb_df['MonthSale'] = melb_df['Date'].dt.month\n",
    "melb_df['MonthSale'].value_counts(normalize=True)\n",
    "\n",
    "з результатов становится ясно, что наибольшее количество продаж недвижимости приходится на май, июль и сентябрь (пятый, седьмой и девятый месяцы соответственно). Месяцами застоя при этом являются месяцы — октябрь, февраль и январь (десятый, второй и первый месяцы соответственно).\n",
    "\n",
    "РАБОТА С ИНТЕРВАЛАМИ\n",
    "\n",
    "Часто бывает такая ситуация, что необходимо вычислять интервалы между двумя временными промежутками. Например, можно вычислить, сколько дней прошло с 1 января 2016 года до момента продажи объекта. Для этого можно просто найти разницу между датами продаж и заявленной датой, представленной в формате datetime:\n",
    "\n",
    "delta_days = melb_df['Date'] - pd.to_datetime('2016-01-01') \n",
    "display(delta_days)\n",
    "\n",
    "В результате мы получаем Series, элементами которой является количество дней, которое прошло с 1 января 2016 года. Обратите внимание, что данные такого формата относятся к типу timedelta.\n",
    "\n",
    "Чтобы превратить количество дней из формата интервала в формат целого числа дней, можно воспользоваться аксессором dt для формата timedelta и извлечь из него атрибут days:\n",
    "\n",
    "display(delta_days.dt.days)\n",
    "\n",
    "Рассмотрим другой пример. Давайте создадим признак возраста объекта недвижимости в годах на момент продажи. Для этого выделим из столбца с датой продажи год и вычтем из него год постройки здания. Результат оформим в виде столбца AgeBuilding:\n",
    "\n",
    "melb_df['AgeBuilding'] = melb_df['Date'].dt.year - melb_df['YearBuilt']\n",
    "display(melb_df['AgeBuilding'])\n",
    "\n",
    "Примечание. Обратите внимание, что, так как года кодируются целым числом, в результате мы тоже получаем целочисленный столбец — тип int64 (а не timedelta).\n",
    "\n",
    "На самом деле столбец AgeBuilding дублирует информацию столбца YearBuilt, так как, зная год постройки здания, мы автоматически знаем его возраст. Такие признаки не стоит оставлять вместе, поэтому оставим возраст здания, так как он является более наглядным, а год постройки удалим из таблицы:\n",
    "\n",
    "melb_df = melb_df.drop('YearBuilt', axis=1)\n",
    "\n",
    "Для таких случаев Pandas не имеет специальных методов, однако позволяет расширить свою функциональность за счёт использования пользовательских функций. \n",
    "\n",
    "Мы можем написать некоторую функцию, которая принимает на вход один элемент столбца, каким-то образом его обрабатывает и возвращает результат, после чего применить эту функцию к каждому элементу в столбце с помощью специального метода apply(). В результате применения этой функции будет возвращён объект Series, элементы которого будут представлять результат работы этой функции.\n",
    "\n",
    "Рассмотрим пример. В наших данных есть столбец с адресами объектов недвижимости. Проблема этого столбца в том, что в нём слишком большое количество уникальных значений: почти на каждый объект недвижимости в таблице приходится свой уникальный адрес. Убедимся в этом, вычислив количество уникальных значений в столбце с помощью метода nunique():\n",
    "\n",
    "print(melb_df['Address'].nunique())\n",
    "# 13378\n",
    "Если мы прогнозируем цену объекта, то такое большое количество возможных категорий может плохо сказаться на модели, которую мы бы хотели в дальнейшем построить на наших данных. Говорят, что такой признак, скорее всего, не имеет статистической значимости, потому что не позволяет разделить данные на группы, которые можно сравнить по целевому признаку.\n",
    "\n",
    "Из-за таких признаков зависимость между целевым признаком, который мы хотим предсказать, и признаками, на основе которых мы делаем предсказание, становится очень сложной. При этом точность моделирования при учёте такого признака может не повыситься, а даже снизиться, а производительность однозначно резко упадёт.\n",
    "\n",
    "Обычно подобные признаки удаляют, однако можно поступить умнее: давайте извлечём из признака адреса характеристику подтипа улицы (улица, шоссе, авеню, бульвар). Для этого сначала внимательнее посмотрим на структуру адреса, выберем несколько строк столбца Address:\n",
    "\n",
    "print(melb_df['Address'].loc[177])\n",
    "print(melb_df['Address'].loc[1812])\n",
    "print(melb_df['Address'].loc[9001])\n",
    "# 2/119 Railway St N\n",
    "# 9/400 Dandenong Rd\n",
    "# 172 Danks St\n",
    "Итак, адрес строится следующим образом: сначала указывается номер дома и корпус, после указывается название улицы, а в конце — подтип улицы, но в некоторых случаях к подтипу добавляется географическая отметка (N — север, S — юг и т. д.), она нам не нужна . Для того чтобы выделить подтип улицы, на которой находится объект, можно использовать следующую функцию:\n",
    "\n",
    "# На вход данной функции поступает строка с адресом.\n",
    "def get_street_type(address):\n",
    "# Создаём список географических пометок exclude_list.\n",
    "    exclude_list = ['N', 'S', 'W', 'E']\n",
    "# Метод split() разбивает строку на слова по пробелу.\n",
    "# В результате получаем список слов в строке и заносим его в переменную address_list.\n",
    "    address_list = address.split(' ')\n",
    "# Обрезаем список, оставляя в нём только последний элемент,\n",
    "# потенциальный подтип улицы, и заносим в переменную street_type.\n",
    "    street_type = address_list[-1]\n",
    "# Делаем проверку на то, что полученный подтип является географической пометкой.\n",
    "# Для этого проверяем его на наличие в списке exclude_list.\n",
    "    if street_type in exclude_list:\n",
    "# Если переменная street_type является географической пометкой,\n",
    "# переопределяем её на второй элемент с конца списка address_list.\n",
    "        street_type = address_list[-2]\n",
    "# Возвращаем переменную street_type, в которой хранится подтип улицы.\n",
    "    return street_type\n",
    "\n",
    "Теперь применим эту функцию к столбцу c адресом. Для этого передадим функцию get_street_type в аргумент метода столбца apply(). В результате получим объект Series, который положим в переменную street_types:\n",
    "\n",
    "street_types = melb_df['Address'].apply(get_street_type)\n",
    "display(street_types)\n",
    "\n",
    "Обратите внимание, что функция пишется для одного элемента столбца, а метод apply() применяется к каждому его элементу. Используемая функция обязательно должна иметь возвращаемое значение.\n",
    "\n",
    "Итак, мы смогли выделить подтип улицы. Посмотрим, сколько уникальных значений у нас получилось:\n",
    "\n",
    "print(street_types.nunique())\n",
    "# 56\n",
    "У нас есть 56 уникальных значений. Однако наш результат можно улучшить. Давайте для начала посмотрим на частоту каждого подтипа улицы с помощью метода value_counts:\n",
    "\n",
    "display(street_types.value_counts())\n",
    "\n",
    "Из данного вывода можно увидеть, что есть группа наиболее популярных подтипов улиц, а дальше частота подтипов быстро падает.\n",
    "\n",
    "В таком случае давайте применим очень распространённый метод уменьшения количества уникальных категорий — выделим n подтипов, которые встречаются чаще всего, а остальные обозначим как 'other' (другие).\n",
    "\n",
    "Для этого к результату метода value_counts применим метод nlargest(), который возвращает n наибольших значений из Series. Зададим n=10, т. е. мы хотим отобрать десять наиболее популярных подтипов. Извлечём их названия с помощью атрибута index, а результат занесём в переменную popular_stypes:\n",
    "\n",
    "popular_stypes =street_types.value_counts().nlargest(10).index\n",
    "print(popular_stypes)\n",
    "# Index(['St', 'Rd', 'Ct', 'Dr', 'Av', 'Gr', 'Pde', 'Pl', 'Cr', 'Cl'], dtype='object')\n",
    "Попробуйте применить использованные методы последовательно и выводить результат, чтобы проследить за логикой преобразования.\n",
    "\n",
    "Теперь, когда у нас есть список наиболее популярных подтипов улиц, введём lambda-функцию, которая будет проверять, есть ли строка x в этом перечне, и, если это так, lambda-функция будет возвращать x, в противном случае она будет возвращать строку 'other'. Наконец, применим такую функцию к Series street_types, полученной ранее, а результат определим в новый столбец таблицы StreetType:\n",
    "\n",
    "melb_df['StreetType'] = street_types.apply(lambda x: x if x in popular_stypes else 'other')\n",
    "display(melb_df['StreetType'])\n",
    "\n",
    "Посмотрим на результирующее число уникальных подтипов:\n",
    "\n",
    "print(melb_df['StreetType'].nunique())\n",
    "# 11\n",
    "Теперь, у нас нет потребности хранить признак Address, так как, если конкретное местоположение объекта всё же и влияет на его стоимость, то оно определяется столбцами Longitude и Lattitude. Удалим его из нашей таблицы:\n",
    "\n",
    "melb_df = melb_df.drop('Address', axis=1)\n",
    "Таким образом, с помощью написания собственных функций и их комбинирования с методом apply() из библиотеки Pandas мы смогли извлечь информацию из признака с адресом и заменить на признак подтипа улицы.\n",
    "\n",
    "Примечание. Внимательный читатель наверняка обратит внимание на то, что мы допустили небольшую ошибку!\n",
    "\n",
    "Если присмотреться, то в списке подтипов улиц street_types можно заметить подтипы, которые именуются различным образом, но при этом обозначают одинаковые вещи. Например, подтипы Av и Avenue, Bvd и Boulevard, Pde и Parade. Мы упустили данный момент, хотя в реальных задачах стоит обращать пристальное внимание на результаты преобразований и исправлять неточности в данных.\n",
    "\n",
    "Такие ошибки в данных (обозначение идентичных категорий различными именами) являются одним из видов «грязных» данных.\n",
    "\n",
    "Порой отследить такие неточности бывает очень сложно, а при наличии большого количества категорий (например, более ста) — практически невозможно.\n",
    "\n",
    "Мы предлагаем вам самостоятельно разобраться с этой ошибкой: попробуйте написать функцию-преобразование (lambda-функцию-преобразование), которая возвращала бы вместо значений Avenue, Boulevard и Parade их топографические сокращения, и примените её к данным о подтипах улиц.\n",
    "\n",
    "→ Обратите внимание, что данное преобразование необходимо применить до сокращения количества уникальных категорий.\n",
    "\n",
    "Резюмируя, поделимся общими рекомендациями по уменьшению числа уникальных значений в признаке, который описывается категориями:\n",
    "\n",
    "1) Определите (хотя бы на глаз) соотношение числа уникальных категорий интересующего вас признака к общему числу объектов в таблице. Если это соотношение превышает значение 30 %, то это уже повод задуматься над уменьшением числа категорий и перейти к шагу 2.\n",
    "\n",
    "2) Если ваш признак уникален для каждого объекта, например адрес, имя или название, то такой признак, скорее всего, не имеет статистической значимости. От таких признаков чаще всего избавляются. Однако можно попробовать выделить из этого признака какие-то общие черты, например, как мы это сделали с подтипами улиц. Такой же трюк можно произвести, например, с названиями компаний, в которых может быть скрыт признак типа организации (из строки «ООО Три Слепые Мыши» можно извлечь ООО — общество с ограниченной ответственностью).\n",
    "\n",
    "3) Если даже после преобразования число уникальных категорий всё ещё велико, можно попробовать с помощью метода value_counts() оценить, есть ли в данных категории, которые употребляются гораздо реже, чем остальные. Если такие категории присутствуют, переходите к шагу 4.\n",
    "\n",
    "4) Можно подобрать число  популярных категорий таким образом, чтобы эти категории покрывали большую часть ваших данных.\n",
    "\n",
    "Когда вы выбрали оптимальное число, переходите к шагу 5.\n",
    "\n",
    "5) Наконец, можно совершить преобразование, обозначив категории, не попавшие в число популярных, как «другие».\n",
    "\n",
    "→ Такая методика является очень популярной и хорошо показывает себя на практике. Однако не нужно ей злоупотреблять: применяя эту методику ко всем столбцам подряд, вы рискуете потерять немалую долю полезной информации из ваших данных. Внимательно изучите интересующий вас признак, прежде чем преобразовывать его.\n",
    "\n",
    "\n",
    "ПРИЗНАКИ: КАТЕГОРИАЛЬНЫЕ И ЧИСЛОВЫЕ\n",
    "\n",
    "Рассмотрим такие статистические термины, как категориальные и числовые признаки.\n",
    "\n",
    "Под числовыми признаками обычно подразумевают признаки, которые отражают количественную меру и могут принимать значения из неограниченного диапазона.\n",
    "\n",
    "Числовые признаки могут быть:\n",
    "\n",
    "дискретными (например, количество комнат, пациентов, дней, отток сотрудников);\n",
    "непрерывными (например, масса, цена, площадь).\n",
    "Дискретные признаки чаще всего представлены целыми числами, а непрерывные — целыми числами и числами с плавающей точкой.\n",
    "\n",
    "Под категориальными признаками обычно подразумевают столбцы в таблице, которые обозначают принадлежность объекта к какому-то классу/категории.\n",
    "\n",
    "Категориальные признаки могут быть:\n",
    "\n",
    "номинальными (например, пол, национальность, район);\n",
    "порядковыми (например, уровень образования, уровень комфорта, стадия заболевания).\n",
    "Такие признаки имеют ограниченный набор значений. Они чаще всего представлены в виде текстового описания и кодируются в Pandas типом данных object.\n",
    "\n",
    "Однако это не всегда так. Например, созданный нами ранее признак месяца продажи кодируется числом (от 1 до 12), но на самом деле является категориальным, поскольку диапазон его значений ограничен и каждому числу мы можем поставить в соответствие название месяца.\n",
    "\n",
    "Возникает вопрос: а какие признаки стоит считать категориальными?\n",
    "\n",
    "Однозначного ответа на этот вопрос нет. Решение, какой признак отнести к классу категорий, остаётся за исследователем. Некоторые специалисты даже относят количественные признаки в разряд категориальных, когда диапазон возможных значений довольно мал. \n",
    "\n",
    "Не существует жёсткого правила, определяющего, сколько значений должна иметь категориальная переменная. Вы должны использовать собственные знания о предметной области, чтобы сделать выбор. Однако в этом разделе мы всё же введём некоторые рекомендации.\n",
    "\n",
    "ПОЧЕМУ ТАК ВАЖНО ОТЛИЧАТЬ КАТЕГОРИАЛЬНЫЕ СТОЛБЦЫ ОТ ДРУГИХ?\n",
    "\n",
    "→ Оказывается, анализ и предобработка категориальных признаков отличается от предобработки числовых признаков.\n",
    "\n",
    "Мы уже видели, что в столбцах с типом данных object мы не можем рассчитать среднее значение, стандартное отклонение или другие статистические параметры, которые годятся только для чисел.\n",
    "\n",
    "Способ заполнения пропущенных данных и поиск аномальных значений также различаются для разных типов признаков, но этот момент мы рассмотрим в модуле по очистке данных.\n",
    "\n",
    "КАТЕГОРИИ В ДАННЫХ О НЕДВИЖИМОСТИ\n",
    "\n",
    "Давайте определим число уникальных категорий в каждом столбце нашей таблицы melb_df. Для этого создадим вспомогательную таблицу unique_counts:\n",
    "\n",
    "# создаём пустой список\n",
    "unique_list = []\n",
    "# пробегаемся по именам столбцов в таблице\n",
    "for col in melb_df.columns:\n",
    "    # создаём кортеж (имя столбца, число уникальных значений)\n",
    "    item = (col, melb_df[col].nunique(),melb_df[col].dtypes) \n",
    "    # добавляем кортеж в список\n",
    "    unique_list.append(item) \n",
    "# создаём вспомогательную таблицу и сортируем её\n",
    "unique_counts = pd.DataFrame(\n",
    "    unique_list,\n",
    "    columns=['Column_Name', 'Num_Unique', 'Type']\n",
    ").sort_values(by='Num_Unique',  ignore_index=True)\n",
    "# выводим её на экран\n",
    "display(unique_counts)\n",
    "\n",
    "Разберём код подробнее:\n",
    "\n",
    "1) Создаём пустой список, в который будем добавлять кортежи: имя столбца, количество уникальных значений в нём и тип столбца.\n",
    "\n",
    "2) В цикле перебираем имена столбцов, которые получаем с помощью атрибута columns. В переменной col на каждой итерации находятся имена столбцов — обращаемся к ним в цикле и извлекаем число уникальных элементов с помощью метода nunique(), а также тип столбца с помощью атрибута dtypes. Результат заносим в кортеж и добавляем его в список.\n",
    "\n",
    "3) Из списка с кортежами (имя столбца, количество уникальных значений в нём, тип столбца) создаём DataFrame, даём названия его столбцам: Column_Name, Num_unique и Type.\n",
    "\n",
    "4) Сортируем таблицу по столбцу Num_unique в порядке возрастания количества уникальных элементов с помощью метода sort_values() и выводим результат на экран.\n",
    "\n",
    "Примечание. Мы ещё не изучали сортировку DataFrame методом sort_values() — данную тему мы обсудим в следующем модуле, однако здесь эта функция необходима для более наглядной интерпретации результата.\n",
    "\n",
    "Итак, с помощью такого несложного кода мы смогли получить вспомогательную таблицу, где в отсортированном виде показано количество уникальных значений во всех столбцах и их типы.\n",
    "\n",
    "Что интересного мы можем узнать из такой таблицы?\n",
    "\n",
    "Если присмотреться внимательно, можно увидеть резкий скачок количества уникальных значений, начиная с 14 строки таблицы, где число уникальных значений составляет 152. Учтём этот момент.\n",
    "\n",
    "Условимся, что категориальными будем считать признаки, у которых число уникальных категорий меньше 150. \n",
    "\n",
    "Однако учтём, что признак Date (дата продажи), преобразованный нами ранее в формат datetime, является временным признаком, поэтому далее не будем его воспринимать как категориальный. \n",
    "\n",
    "К тому же в наш потенциальный список попали количественные столбцы Rooms, Car, Bedroom и Bathroom. Договоримся, что мы не будем относить их к разряду категориальных, однако, как упоминалось ранее, такое тоже вполне возможно.\n",
    "\n",
    "Примечание. Ещё раз подчеркиваем, что такая классификация признаков является исключительно субъективной и специфична для задачи.\n",
    "\n",
    "ТИП ДАННЫХ CATEGORY\n",
    "\n",
    "Для хранения и оптимизации работы с категориальными признаками в Pandas предусмотрен специальный тип данных — category.\n",
    "\n",
    "→ Этот тип данных является гибридным: внешне он выглядит как строка, но внутренне представлен массивом целых чисел. Так как данные вместо изначальных строк хранятся в памяти как число, то объём памяти, занимаемой таблицей при использовании типа category, резко уменьшается, что повышает эффективность хранения и работы с таблицей.\n",
    "\n",
    "→ Более того, этот тип данных расширяет возможности работы с категориальными признаками: мы можем легко преобразовывать категории, строить графики по таким данным (что сложно сделать для типа данных object). Также резко повышается производительность операций, совершаемых с такими столбцами.\n",
    "\n",
    "Самый простой способ преобразования столбцов к типу данных category — это использование уже знакомого нам метода astype(), в параметры которого достаточно передать строку 'category'.\n",
    "\n",
    "Рассмотрим это на примере.\n",
    "\n",
    "Для начала, выведем информацию о памяти, занимаемой текущей таблицей, с помощью метода info():\n",
    "\n",
    "display(melb_df.info())\n",
    "Текущий объём памяти — 2.7 Мб.\n",
    "\n",
    "Примечание. Объём занимаемой памяти и количество столбцов на вашем компьютере может отличаться в зависимости от того, выполняли ли вы код и задания из предыдущих разделов на добавление и преобразование данных в таблице.\n",
    "\n",
    "Сделаем преобразование столбцов к типу данных category:\n",
    "\n",
    "cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] # список столбцов, которые мы не берём во внимание\n",
    "max_unique_count = 150 # задаём максимальное число уникальных категорий\n",
    "for col in melb_df.columns: # цикл по именам столбцов\n",
    "    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: # проверяем условие\n",
    "        melb_df[col] = melb_df[col].astype('category') # преобразуем тип столбца\n",
    "display(melb_df.info())\n",
    "\n",
    "Разберём код подробнее:\n",
    "\n",
    "1) Задаём список столбцов, которые мы не берём в рассмотрение (cols_to_exclude), а также условленный нами ранее порог уникальных значений столбца max_unique_count.\n",
    "\n",
    "2) В цикле перебираем имена столбцов, и, если число уникальных категорий меньше заданного порога и имён столбцов нет в списке cols_to_exclude, то с помощью метода astype() приводим столбец к типу данных category.\n",
    "\n",
    "3) Итоговый объём памяти — 1.9 Мб. В результате такого преобразования объём памяти, занимаемый таблицей, уменьшился почти в 1.5 раза. Это впечатляет!\n",
    "\n",
    "Особенно хорошо такое преобразование работает на действительно больших данных, где число строк превышает сотни тысяч или миллионы. Иногда изменение типов может уменьшить объём памяти в десятки раз и существенно увеличить производительность.\n",
    "\n",
    "ПОЛУЧЕНИЕ АТРИБУТОВ CATEGORY\n",
    "\n",
    "У типа данных category есть свой специальный аксесcор cat, который позволяет получать информацию о своих значениях и преобразовывать их. Например, с помощью атрибута этого аксессора categories мы можем получить список уникальных категорий в столбце Regionname:\n",
    "\n",
    "print(melb_df['Regionname'].cat.categories)\n",
    "\n",
    "А теперь посмотрим, каким образом столбец кодируется в виде чисел в памяти компьютера. Для этого можно воспользоваться атрибутом codes:\n",
    "\n",
    "display(melb_df['Regionname'].cat.codes)\n",
    "\n",
    "С помощью метода аксессора rename_categories() можно легко переименовать текущие значения категорий. Для этого в данный метод нужно передать словарь, ключи которого — старые имена категорий, а значения — новые.\n",
    "\n",
    "Рассмотрим на примере: переименуем категории признака типа постройки Type — заменим их на полные названия (напомним, u — unit, h — house, t — townhouse).\n",
    "\n",
    "melb_df['Type'] = melb_df['Type'].cat.rename_categories({\n",
    "    'u': 'unit',\n",
    "    't': 'townhouse',\n",
    "    'h': 'house'\n",
    "})\n",
    "display(melb_df['Type'])\n",
    "\n",
    "ПОДВОДНЫЕ КАМНИ\n",
    "\n",
    "А теперь представим ситуацию, что появилась новая партия домов и теперь мы продаём и квартиры (flat). Создадим объект Series new_houses_types, в котором будем хранить типы зданий новой партии домов. Преобразуем тип new_houses_types в такой же тип, как и у столбца Type в таблице melb_data, и выведем результат на экран:\n",
    "\n",
    "new_houses_types = pd.Series(['unit', 'house', 'flat', 'flat', 'house'])\n",
    "new_houses_types = new_houses_types.astype(melb_df['Type'].dtype)\n",
    "display(new_houses_types)\n",
    "\n",
    "Хммм... С нашими новыми объектами недвижимости произошло нечто странное. По какой-то причине вместо квартир мы получили пустые значения — NaN.\n",
    "\n",
    "На самом деле причина проста: тип данных category хранит только категории, которые были объявлены при его инициализации. При встрече с новой, неизвестной ранее категорией, этот тип превратит её в пустое значение, так как он просто не знает о существовании этой категории.\n",
    "\n",
    "Решить эту проблему на самом деле не сложно. Можно добавить категорию flat в столбец Type с помощью метода акссесора cat add_categories(), в который достаточно просто передать имя новой категории:\n",
    "\n",
    "melb_df['Type'] = melb_df['Type'].cat.add_categories('flat')\n",
    "new_houses_types = pd.Series(['unit', 'house', 'flat', 'flat', 'house'])\n",
    "new_houses_types = new_houses_types.astype(melb_df['Type'].dtype)\n",
    "display(new_houses_types)\n",
    "\n",
    "Примечание. Добавление новой категории в столбец Type не отразится на самом столбце — текущие категории не изменятся, однако такое преобразование позволит добавлять в таблицу новые данные о домах с новой категорией — flat.\n",
    "\n",
    "Из данного примера можно сделать вывод, что если набор категорий в столбце жёстко не зафиксирован и может обновляться в процессе работы, то тип category не является подходящим типом данных для этого столбца или необходимо постоянно писать проверки при обновлении таблицы.\n",
    "\n",
    "Теперь, когда мы рассмотрели основные моменты и нюансы работы с типом данных category, можно сформулировать несколько рекомендаций по его использованию:\n",
    "\n",
    "1) Необязательно каждый раз преобразовывать категориальные данные в тип данных category. Зачастую это делается исключительно для оптимизации работы с большими данными.\n",
    "\n",
    "2) Если набор данных занимает значительный процент используемой оперативной памяти, рассмотрите возможность использования типа category.\n",
    "\n",
    "3) Если у вас очень серьёзные проблемы с производительностью, обратите внимание на использование типа category.\n",
    "\n",
    "4) Если вы решили использовать тип category, будьте осторожны при добавлении новой информации в вашу таблицу. Убедитесь, что вы собрали всю необходимую информацию, произведите предобработку данных и только после этого используйте преобразование типов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>...</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>Coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019</td>\n",
       "      <td>-37.7996, 144.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019</td>\n",
       "      <td>-37.8079, 144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019</td>\n",
       "      <td>-37.8093, 144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019</td>\n",
       "      <td>-37.7969, 144.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019</td>\n",
       "      <td>-37.8072, 144.9941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Suburb           Address  Rooms Type      Price Method SellerG  \\\n",
       "0      0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "1      1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "2      2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "3      3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n",
       "4      4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n",
       "\n",
       "        Date  Distance  ...  Car  Landsize  BuildingArea  YearBuilt  \\\n",
       "0  3/12/2016       2.5  ...    1     202.0         126.0       1970   \n",
       "1  4/02/2016       2.5  ...    0     156.0          79.0       1900   \n",
       "2  4/03/2017       2.5  ...    0     134.0         150.0       1900   \n",
       "3  4/03/2017       2.5  ...    1      94.0         126.0       1970   \n",
       "4  4/06/2016       2.5  ...    2     120.0         142.0       2014   \n",
       "\n",
       "   CouncilArea  Lattitude  Longtitude             Regionname  Propertycount  \\\n",
       "0        Yarra   -37.7996    144.9984  Northern Metropolitan           4019   \n",
       "1        Yarra   -37.8079    144.9934  Northern Metropolitan           4019   \n",
       "2        Yarra   -37.8093    144.9944  Northern Metropolitan           4019   \n",
       "3        Yarra   -37.7969    144.9969  Northern Metropolitan           4019   \n",
       "4        Yarra   -37.8072    144.9941  Northern Metropolitan           4019   \n",
       "\n",
       "          Coordinates  \n",
       "0  -37.7996, 144.9984  \n",
       "1  -37.8079, 144.9934  \n",
       "2  -37.8093, 144.9944  \n",
       "3  -37.7969, 144.9969  \n",
       "4  -37.8072, 144.9941  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melb_data = pd.read_csv('C:/Users/ilyad/IDE/study/python_11/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "melb_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melse\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 55\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_of_day\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstarttime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mhour\u001b[38;5;241m.\u001b[39mapply(get_time_of_day)\n\u001b[0;32m     56\u001b[0m a \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_of_day\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     57\u001b[0m b \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_of_day\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ilyad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6296\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6290\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6291\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6294\u001b[0m ):\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ilyad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\ilyad\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "citibike_tripdata = pd.read_csv('C:/Users/ilyad/IDE/study/python_11/citibike-tripdata.csv', sep=',')\n",
    "data = citibike_tripdata.copy()\n",
    "data.head()\n",
    "\n",
    "#ЗАДАНИЕ 6.3\n",
    "#print(data['start station id'].mode()[0])\n",
    "\n",
    "#ЗАДАНИЕ 6.4\n",
    "#print(data['bikeid'].mode()[0])\n",
    "\n",
    "#ЗАДАНИЕ 6.5\n",
    "#mode_usertype = data['usertype'].mode()[0]\n",
    "#count_mode_user = data[data['usertype'] == mode_usertype].shape[0]\n",
    "#print(round(count_mode_user / data.shape[0], 2))\n",
    "\n",
    "#ЗАДАНИЕ 6.6\n",
    "#male_count = data[data['gender'] == 1].shape[0]\n",
    "#female_count = data[data['gender'] == 0].shape[0]\n",
    "#print(max([male_count, female_count]))\n",
    "\n",
    "#ЗАДАНИЕ 6.8\n",
    "#data.drop(['start station id', 'end station id'], axis=1, inplace=True)\n",
    "#print(data.shape[1])\n",
    "\n",
    "#ЗАДАНИЕ 6.9\n",
    "#data['age'] = 2018 - data['birth year']\n",
    "#data.drop(['birth year'], axis=1, inplace=True)\n",
    "#print(data[data['age'] > 60].shape[0])\n",
    "\n",
    "#ЗАДАНИЕ 6.10\n",
    "#data['starttime'] = pd.to_datetime(data['starttime'])\n",
    "#data['stoptime'] = pd.to_datetime(data['stoptime'])\n",
    "#data['trip duration'] = (data['stoptime'] - data['starttime'])\n",
    "#print(data.loc[3, 'trip duration'])\n",
    "\n",
    "#ЗАДАНИЕ 6.11\n",
    "#weekday = data['starttime'].dt.dayofweek\n",
    "#data['weekend'] = weekday.apply(lambda x: 1 if x ==5 or x == 6 else 0)\n",
    "#data['weekend'].sum()\n",
    "\n",
    "#ЗАДАНИЕ 6.12\n",
    "def get_time_of_day(time):\n",
    "    if 0 <= time <= 6:\n",
    "        return 'night'\n",
    "    elif 6 < time <= 12:\n",
    "        return 'morning'\n",
    "    elif 12 < time <= 18:\n",
    "        return 'day'\n",
    "    elif 18 < time <= 23:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'else'\n",
    "data['time_of_day'] = data['starttime'].dt.hour.apply(get_time_of_day)\n",
    "a = data[data['time_of_day'] == 'day'].shape[0]\n",
    "b = data[data['time_of_day'] == 'night'].shape[0]\n",
    "print(round(a / b))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
