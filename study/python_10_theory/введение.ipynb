{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека Pandas является стандартным пакетом в Anaconda, поэтому, если вы уже используете эту среду, устанавливать Pandas не нужно. Если же вы не используете Anaconda, то пакет устанавливается стандартно:\n",
    "\n",
    "pip install pandas\n",
    "В общепринятой практике Pandas импортируется и используется под псевдонимом pd:\n",
    "\n",
    "import pandas as pd\n",
    "Чтобы удостовериться, что импорт прошёл успешно, можно воспользоваться командой для проверки версии библиотеки:\n",
    "\n",
    "pd.__version__\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "\n",
    "Для того чтобы лучше разобраться в материале, советуем вам выполнять весь код, который используется в модуле.\n",
    "\n",
    "Ваша версия библиотеки может отличаться, так как Pandas не стоит на месте и постоянно обновляется.\n",
    "\n",
    "Если библиотека импортирована под псевдонимом, то в дальнейшем, обращаясь к методам и классам из этой библиотеки, необходимо использовать заданный псевдоним, например pd.get_dummies()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series — это упорядоченная изменяемая коллекция объектов, имеющая так называемые ассоциативные метки (индексы). \n",
    "\n",
    "Также для каждой Series присваивается тип данных её элементов (например int64) и может быть определено имя всего массива. В итоге мы получаем некоторый гибрид списка и словаря.\n",
    "\n",
    "Series в какой-то степени является единицей хранения информации в Pandas. Её можно рассматривать как именованный столбец таблицы с индексами строк.\n",
    "\n",
    "Для создания объекта Series используется команда pd.Series().\n",
    "\n",
    "Доступ к элементам осуществляется с использованием loc или iloc.\n",
    "\n",
    ".loc вызывается с квадратными скобками, в которые передаются метки. В него можно передать как один индекс, так и список, чтобы получилось несколько элементов. \n",
    ".iloc также вызывается с квадратными скобками и принимает на вход порядковые номера элементов Series (нумерация начинаются с 0). В него можно так же передавать как один индекс, так и диапазон чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame является двумерной структурой и представляется в виде таблицы, в которой есть строки и столбцы: столбцами в DataFrame выступают объекты Series, а строки формируются из их элементов. Также в DataFrame есть метки (индексы), которые соответствуют каждой строке таблицы.\n",
    "\n",
    "Приведём пример такой структуры:\n",
    "\n",
    "ФИО\tВОЗРАСТ\tДОХОД\tРАЗМЕР КРЕДИТА\n",
    "0\tИванов И. И.\t32\t120\t250\n",
    "1\tАвербух А. В.\t28\t44\t320\n",
    "2\tВестяк А. В.\t86\t250\t500\n",
    "Примечание. В дальнейшем слова DataFrame и таблица будут употребляться как синонимы. Также синонимами в Data Science являются слова столбец таблицы и признак.\n",
    "\n",
    "DataFrame создаётся с помощью функции pd.DataFrame(). Так же, как и для Series, для создания объектов DataFrame есть несколько способов:\n",
    "\n",
    "СПОСОБ 1\n",
    "\n",
    "Самый простой способ создания DataFrame — из словаря, ключами которого являются имена столбцов будущей таблицы, а значениями — списки, в которых хранится содержимое этих столбцов\n",
    "\n",
    "СПОСОБ 2\n",
    "\n",
    "Также DataFrame можно создать из вложенного списка, внутренние списки которого будут являться строками новой таблицы\n",
    "\n",
    "При работе с Pandas важно уметь указывать направление работы метода, который используется. Для этого вводится понятие axis (ось, координата). Движение по строкам в таблице обозначается axis с индексом 0, а движение по столбцам — axis с индексом 1.\n",
    "\n",
    "Данный параметр заложен во все методы, которые могут работать в двух направлениях и по умолчанию в большинстве из них axis=0, то есть они выполняют операции со строками, если не задавать axis вручную.\n",
    "\n",
    "Доступ к столбцу можно получить разными способами:\n",
    "\n",
    "Можно обратиться к DataFrame по имени столбца через точку:\n",
    "countries_df.population\n",
    "Однако использование такого способа возможно только тогда, когда имя столбца указано без пробелов.\n",
    "\n",
    "Другой вариант — обратиться к DataFrame по индексу и указать имя столбца:\n",
    "countries_df['population']\n",
    "\n",
    "Примечание. Обратите внимание, что, как и ожидалось, при обращении к столбцу DataFrame мы получаем объект Series с именем, соответствующим имени столбца. Удостовериться в этом можно с помощью функции type():\n",
    "\n",
    "type(countries_df.population)\n",
    "# pandas.core.series.Series\n",
    "Для того чтобы получить доступ к ячейкам таблицы, используются уже знакомые нам loc и iloc.\n",
    "\n",
    "При этом, в соответствии с механизмом работы axis, при обращении к DataFrame по индексам с помощью loc (iloc) первым индексом указывается индекс (порядковый номер), соответствующий строкам, а вторым — имя (порядковый номер) столбца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАПИСЬ В CSV-ФАЙЛ\n",
    "\n",
    "Предположим, что мы захотели сохранить созданный нами ранее DataFrame. Самым простым и распространённым источником табличных данных является формат csv (comma-separated values). В данном формате ячейки таблицы обозначаются некоторым разделителем, чаще всего запятой либо точкой с запятой.\n",
    "\n",
    "Экспорт данных в формат csv осуществляется с помощью метода DataFrame to_csv().\n",
    "\n",
    "Основные параметры метода DataFrame to_csv()\n",
    "\n",
    "path_or_buf — путь до файла, в который будет записан DataFrame (например, data/my_data.csv);\n",
    "sep — разделитель данных в выходном файле (по умолчанию ',');\n",
    "decimal — разделитель чисел на целую и дробную части в выходном файле (по умолчанию '.');\n",
    "columns — список столбцов, которые нужно записать в файл (по умолчанию записываются все столбцы);\n",
    "index — параметр, определяющий, требуется ли создавать дополнительный столбец с индексами строк в файле (по умолчанию True).\n",
    "\n",
    "Основные параметры функции read_csv()\n",
    "\n",
    "filepath_or_buffer — путь до файла, который мы читаем;\n",
    "sep — разделитель данных (по умолчанию ',');\n",
    "decimal — разделитель чисел на целую и дробную часть в выходном файле (по умолчанию '.');\n",
    "names — список с названиями столбцов для чтения;\n",
    "skiprows — количество строк в файле, которые нужно пропустить (например, файл может содержать служебную информацию, которая нам не нужна).\n",
    "\n",
    "ЧТЕНИЕ CSV-ФАЙЛА ПО ССЫЛКЕ\n",
    "\n",
    "На самом деле файл с данными не обязательно должен храниться у вас на компьютере. Если он находится в открытом доступе по ссылке (например, на Google Диске или GitHub), его можно прочитать и из интернета — для этого достаточно в функции read_csv() вместо пути до файла указать ссылку на файл. Например:\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv')\n",
    "display(data)\n",
    "→ Данные, прочитанные выше, ещё понадобятся нам в этом модуле, а пока предлагаем ознакомиться ещё с несколькими методами.\n",
    "\n",
    "ЗАПИСЬ И ЧТЕНИЕ В ДРУГИХ ФОРМАТАХ\n",
    "\n",
    "Как уже говорилось ранее, Pandas способен работать со многими распространёнными форматами данных.\n",
    "\n",
    "Методы для записи таблиц в файлы отличных от csv форматов:\n",
    "\n",
    "to_excel() — запись DataFrame в формат Excel-таблицы (.xlsx);\n",
    "to_json() — запись DataFrame в формат JSON (.json);\n",
    "to_xml() — запись DataFrame в формат XML-документа (.xml);\n",
    "to_sql() — запись DataFrame в базу данных SQL (для реализации этого метода необходимо установить соединение с базой данных).\n",
    "Методы для чтения таблиц из файлов в отличных от csv форматах:\n",
    "\n",
    "read_excel() — чтение из формата Excel-таблицы (.xlsx) в DataFrame;\n",
    "read_json() — чтение из формата JSON (.json) в DataFrame;\n",
    "read_xml() — чтение из формата XML-документа (.xml) в DataFrame;\n",
    "read_sql() — чтение из базы данных SQL в DataFrame (также необходимо установить соединение с базой данных).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('C:/Users/ilyad/IDE/study/python_10_theory/melb_data.csv', sep=',')\n",
    "round(melb_data.loc[3521, 'Landsize'] / melb_data.loc[1690, 'Landsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД ПЕРВЫХ И ПОСЛЕДНИХ СТРОК\n",
    "\n",
    "→ Часто бывает такое, что вывести на экран все строки таблицы является ресурсозатратной операцией, а иногда и вовсе не представляется возможным. В большинстве случаев для того, чтобы понять структуру DataFrame и удостовериться, что таблица подгрузилась верно, достаточно вывести несколько первых или последних строк.\n",
    "Для этого у DataFrame есть методы head() и tail(), которые возвращают n первых и n последних строк таблицы соответственно (по умолчанию n = 5).\n",
    "\n",
    "РАЗМЕРНОСТЬ ТАБЛИЦЫ\n",
    "\n",
    "Далее хотелось бы узнать размер таблицы — количество строк и количество столбцов. Это можно сделать с помощью атрибута shape, который возвращает кортеж с количеством строк и столбцов:\n",
    " melb_data.shape\n",
    "\n",
    " ПОЛУЧЕНИЕ ИНФОРМАЦИИ О СТОЛБЦАХ\n",
    "\n",
    "Для того чтобы получить более детальную информацию о столбцах таблицы, можно использовать метод DataFrame info():\n",
    "melb_data.info()\n",
    "Данный метод выводит:\n",
    "информацию об индексах;\n",
    "информацию об общем количестве столбцов;\n",
    "таблицу, в которой содержится информация об именах столбцов (Column), количестве непустых значений (Non-Null Count) в каждом столбце и типе данных столбца (Dtype), количестве столбцов, в которых используется определённый тип данных;\n",
    "количество оперативной памяти в мегабайтах, которое тратится на хранение данных.\n",
    "\n",
    "ИЗМЕНЕНИЕ ТИПА ДАННЫХ В СТОЛБЦЕ\n",
    "\n",
    "→ Если присмотреться внимательнее к выводу метода info(), а конкретнее — к типам данных столбцов, становится понятно, что некоторые признаки кодируются не совсем корректными типами данных. \n",
    "Например, данные в столбцах, которые отражают количество, должны, по идее, выражаться целым числом (Car, Bedroom, Bathroom и Propertyсount), однако кодируются float64 — числом с плавающей запятой размером 64 бита.\n",
    "Наконец, данные в столбце с годом постройки (YearBuilt) также представлены в формате чисел с плавающей точкой.\n",
    "Чтобы исправить это, можно воспользоваться методом astype(), который позволяет преобразовать тип данных столбца:\n",
    "melb_data['Car'] = melb_data['Car'].astype('int64')\n",
    "melb_data['Bedroom'] = melb_data['Bedroom'].astype('int64')\n",
    "melb_data['Bathroom'] = melb_data['Bathroom'].astype('int64')\n",
    "melb_data['Propertycount'] = melb_data['Propertycount'].astype('int64')\n",
    "melb_data['YearBuilt'] = melb_data['YearBuilt'].astype('int64')\n",
    "melb_data.info()\n",
    "\n",
    "ПОЛУЧЕНИЕ ОПИСАТЕЛЬНОЙ СТАТИСТИКИ\n",
    "\n",
    "→ Часто при работе с таблицей нужно быстро посмотреть на основные статистические свойства её столбцов. Для этого можно воспользоваться методом DataFrame describe().\n",
    "\n",
    "→ На самом деле метод describe() можно применять не только к числовым признакам. С помощью параметра include можно указать тип данных, для которого нужно вывести описательную информацию.\n",
    "Например, для типа данных object метод describe() возвращает DataFrame, в котором указаны:\n",
    "количество непустых строк (count);\n",
    "количество уникальных значений (unique);\n",
    "самое частое значение — мода —  (top);\n",
    "частота — объём использования — этого значения (freq) для каждого столбца типа object исходной таблицы.\n",
    "melb_data.describe(include=['object'])\n",
    "\n",
    "ПОЛУЧЕНИЕ ЧАСТОТЫ УНИКАЛЬНЫХ ЗНАЧЕНИЙ В СТОЛБЦЕ\n",
    "\n",
    "→ Для того чтобы определить, сколько раз в столбце повторяется каждый из вариантов значений (т.е. найти частоту для каждого уникального знания), используется метод value_counts().\n",
    "Данный метод возвращает объект Series, в котором в качестве индексов выступают уникальные категории столбца, а значениями — соответствующая им частота.\n",
    "Рассмотрим работу value_counts() на примере столбца с названиями районов:\n",
    "melb_data['Regionname'].value_counts()\n",
    "Чтобы сделать вывод более интерпретируемым и понятным, можно воспользоваться параметром normalize. При установке значения этого параметра на True результат будет представляться в виде доли (относительной частоты):\n",
    "melb_data['Regionname'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Агрегирующим в Pandas называется метод, который для каждого столбца возвращает только одно значение — показатель (например, вычисление медианы, максимума, среднего и так далее).\n",
    "\n",
    "Ниже приведена таблица основных агрегирующих методов:\n",
    "\n",
    "МЕТОД\tСТАТИСТИЧЕСКИЙ ПАРАМЕТР\n",
    ".count()\tКоличество непустых значений\n",
    ".mean()\tСреднее значение\n",
    ".min()\tМинимальное значение\n",
    ".max()\tМаксимальное значение\n",
    ".var()\tДисперсия\n",
    ".std()\tСтандартное отклонение\n",
    ".sum()\tСумма\n",
    ".quantile(x)\tКвантиль уровня x\n",
    ".nunique()\tЧисло уникальных значений\n",
    "Если один из этих методов применить ко всему DataFrame, то в результате его работы будет получен объект типа Series, в котором в качестве индексов будут выступать наименования столбцов, а в качестве значений — статистический показатель. В случае применения метода к отдельному столбцу результатом вычислений станет число.\n",
    "\n",
    "В каждый метод можно передать некоторые параметры, среди которых:\n",
    "\n",
    "axis  — определяет, подсчитывать параметр по строкам или по столбцам;\n",
    "numeric_only — определяет, вычислять параметры только по числовым столбцам/строкам или нет (True/False).\n",
    "\n",
    "МОДАЛЬНОЕ ЗНАЧЕНИЕ\n",
    "\n",
    "→ Отдельный интерес представляет статический показатель моды — самого распространённого значения в столбце. Он вычисляется с помощью метода mode().\n",
    "\n",
    "Модальных значений может быть несколько, то есть несколько значений могут встречаться одинаковое количество раз. Поэтому метод mode(), в отличие от агрегирующих методов, возвращает не одно число, а серию.\n",
    "\n",
    "Примечание. Метод mode() может быть использован не только с числовыми столбцами, но и со столбцами типа object. Так, например, с помощью следующего кода можно найти наиболее распространённое название района:\n",
    "\n",
    "melb_data['Regionname'].mode()\n",
    "\n",
    "\n",
    "Часто возникает необходимость исследовать определённую группу объектов по какому-то условию, например найти здания с ценой меньше 1 миллиона или выделить из всей таблицы помещения с двумя комнатами.\n",
    "\n",
    "Такие задачи называются задачами фильтрации.\n",
    "\n",
    "Под фильтрацией в DataFrame подразумевается получение новой таблицы путём вырезания строк, не удовлетворяющих поставленному условию. \n",
    "\n",
    "Разберём классический способ фильтрации в DataFrame — фильтрацию с помощью масок.\n",
    "\n",
    "Маской называется Series, которая состоит из булевых значений, при этом значения True соответствуют тем индексам, для которых заданное условие выполняется, в противном случае ставится значение False (например, цена > 2 млн).\n",
    "\n",
    "Создадим маску и положим её в переменную с именем mask. Синтаксис очень прост:\n",
    "\n",
    "mask = melb_data['Price'] > 2000000\n",
    "display(mask)\n",
    "\n",
    "Для фильтрации нужно просто подставить переменную mask в индексацию DataFrame. Маска показывает, какие строки нужно оставлять в результирующем наборе, а какие — убирать (выведем первые пять строк отфильтрованной таблицы):\n",
    "\n",
    "display(melb_data[mask].head())\n",
    "\n",
    "\n",
    "Примечание. В результате выполнения фильтрации возвращается новый DataFrame, полученный из исходного, при этом исходная таблица melb_data остаётся без изменений.\n",
    "\n",
    "Также вовсе не обязательно заносить маску в отдельную переменную — можно сразу вставлять условие в операцию индексации DataFrame, например:\n",
    "\n",
    "melb_data[melb_data['Price'] > 2000000]\n",
    "Найдём количество зданий с тремя комнатами. Для этого отфильтруем таблицу по условию: обратимся к результирующей таблице по столбцу Rooms и найдём число строк в ней с помощью атрибута shape:\n",
    "\n",
    "melb_data[melb_data['Rooms'] == 3].shape[0]\n",
    "# 5881\n",
    "Условия можно комбинировать, используя операторы & (логическое И) и | (логическое ИЛИ). Условия при этом заключаются в скобки.\n",
    "\n",
    "Усложним прошлый пример и найдём число трёхкомнатных домов с ценой менее 300 тысяч:\n",
    "\n",
    "melb_data[(melb_data['Rooms'] == 3) & (melb_data['Price'] < 300000)].shape[0]\n",
    "# 3\n",
    "Таких зданий оказалось всего три. Немного «ослабим» условие: теперь нас будут интересовать дома с ценой менее 300 тысяч, у которых либо число комнат равно 3 либо площадь домов более 100 квадратных метров:\n",
    "\n",
    "melb_data[((melb_data['Rooms'] == 3) | (melb_data['BuildingArea'] > 100)) & (melb_data['Price'] < 300000)].shape[0]\n",
    "# 68\n",
    "\n",
    "Примечание. Обратите внимание, что использование привычных операторов and и or будет неверным и приведёт к ошибке, так как они выполняют логические операции между двумя булевыми числами. В нашем случае слева и справа от оператора стоят маски (объекты Series), для которых логическую операцию надо совершить поэлементно, а операторы and и or для такого не предназначены.\n",
    "\n",
    "Фильтрацию часто сочетают со статистическими методами. Давайте найдём максимальное количество комнат в таунхаусах. Так как в результате фильтрации получается DataFrame, то обратимся к нему по столбцу Rooms и найдём максимальное значение:\n",
    "\n",
    "melb_data[melb_data['Type'] == 't']['Rooms'].max()\n",
    "# 5\n",
    "А теперь более сложный трюк: найдём медианную площадь здания у объектов, чья цена выше средней. Для того чтобы оградить наш код от нагромождений, предварительно создадим переменную со средней ценой:\n",
    "\n",
    "mean_price = melb_data['Price'].mean()\n",
    "melb_data[melb_data['Price'] > mean_price]['BuildingArea'].median()\n",
    "\n",
    "# 126.0\n",
    "Фильтрация находит применение в очистке данных.\n",
    "\n",
    "Под очисткой данных понимается удаление из данных аномальных значений (выбросов), пропусков и данных, которые не несут информацию.\n",
    "\n",
    "Причин появления таких дефектов в данных множество: неправильная передача по сети, неверная выгрузка из базы, человеческий фактор и т. д.\n",
    "\n",
    "→ Проблема аномальных значений состоит в том, что если мы обучаем модель на данных, содержащих выбросы, то мы имеем немалый шанс получить менее верный прогноз, чего нам, конечно же, не хотелось бы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "5\n",
      "412500.0\n",
      "769239\n",
      "0    Northern Metropolitan\n",
      "Name: Regionname, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('C:/Users/ilyad/IDE/study/python_10_theory/melb_data.csv', sep=',')\n",
    "\n",
    "print(melb_data[melb_data['Bathroom'] == 0].shape[0])\n",
    "\n",
    "print(melb_data[(melb_data['SellerG'] == 'Nelson') & (melb_data['Price'] > 3e6)].shape[0])\n",
    "\n",
    "print(melb_data[(melb_data['BuildingArea'] == 0)]['Price'].min())\n",
    "\n",
    "print(round(melb_data[(melb_data['Price']<1e6) & ((melb_data['Rooms']>5) | (melb_data['YearBuilt'] > 2015))]['Price'].mean()))\n",
    "\n",
    "print(melb_data[(melb_data['Type'] == 'h') & (melb_data['Price'] < 3000000)]['Regionname'].mode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
