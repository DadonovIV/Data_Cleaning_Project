{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека Pandas является стандартным пакетом в Anaconda, поэтому, если вы уже используете эту среду, устанавливать Pandas не нужно. Если же вы не используете Anaconda, то пакет устанавливается стандартно:\n",
    "\n",
    "pip install pandas\n",
    "В общепринятой практике Pandas импортируется и используется под псевдонимом pd:\n",
    "\n",
    "import pandas as pd\n",
    "Чтобы удостовериться, что импорт прошёл успешно, можно воспользоваться командой для проверки версии библиотеки:\n",
    "\n",
    "pd.__version__\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "\n",
    "Для того чтобы лучше разобраться в материале, советуем вам выполнять весь код, который используется в модуле.\n",
    "\n",
    "Ваша версия библиотеки может отличаться, так как Pandas не стоит на месте и постоянно обновляется.\n",
    "\n",
    "Если библиотека импортирована под псевдонимом, то в дальнейшем, обращаясь к методам и классам из этой библиотеки, необходимо использовать заданный псевдоним, например pd.get_dummies()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series — это упорядоченная изменяемая коллекция объектов, имеющая так называемые ассоциативные метки (индексы). \n",
    "\n",
    "Также для каждой Series присваивается тип данных её элементов (например int64) и может быть определено имя всего массива. В итоге мы получаем некоторый гибрид списка и словаря.\n",
    "\n",
    "Series в какой-то степени является единицей хранения информации в Pandas. Её можно рассматривать как именованный столбец таблицы с индексами строк.\n",
    "\n",
    "Для создания объекта Series используется команда pd.Series().\n",
    "\n",
    "Доступ к элементам осуществляется с использованием loc или iloc.\n",
    "\n",
    ".loc вызывается с квадратными скобками, в которые передаются метки. В него можно передать как один индекс, так и список, чтобы получилось несколько элементов. \n",
    ".iloc также вызывается с квадратными скобками и принимает на вход порядковые номера элементов Series (нумерация начинаются с 0). В него можно так же передавать как один индекс, так и диапазон чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame является двумерной структурой и представляется в виде таблицы, в которой есть строки и столбцы: столбцами в DataFrame выступают объекты Series, а строки формируются из их элементов. Также в DataFrame есть метки (индексы), которые соответствуют каждой строке таблицы.\n",
    "\n",
    "Приведём пример такой структуры:\n",
    "\n",
    "ФИО\tВОЗРАСТ\tДОХОД\tРАЗМЕР КРЕДИТА\n",
    "0\tИванов И. И.\t32\t120\t250\n",
    "1\tАвербух А. В.\t28\t44\t320\n",
    "2\tВестяк А. В.\t86\t250\t500\n",
    "Примечание. В дальнейшем слова DataFrame и таблица будут употребляться как синонимы. Также синонимами в Data Science являются слова столбец таблицы и признак.\n",
    "\n",
    "DataFrame создаётся с помощью функции pd.DataFrame(). Так же, как и для Series, для создания объектов DataFrame есть несколько способов:\n",
    "\n",
    "СПОСОБ 1\n",
    "\n",
    "Самый простой способ создания DataFrame — из словаря, ключами которого являются имена столбцов будущей таблицы, а значениями — списки, в которых хранится содержимое этих столбцов\n",
    "\n",
    "СПОСОБ 2\n",
    "\n",
    "Также DataFrame можно создать из вложенного списка, внутренние списки которого будут являться строками новой таблицы\n",
    "\n",
    "При работе с Pandas важно уметь указывать направление работы метода, который используется. Для этого вводится понятие axis (ось, координата). Движение по строкам в таблице обозначается axis с индексом 0, а движение по столбцам — axis с индексом 1.\n",
    "\n",
    "Данный параметр заложен во все методы, которые могут работать в двух направлениях и по умолчанию в большинстве из них axis=0, то есть они выполняют операции со строками, если не задавать axis вручную.\n",
    "\n",
    "Доступ к столбцу можно получить разными способами:\n",
    "\n",
    "Можно обратиться к DataFrame по имени столбца через точку:\n",
    "countries_df.population\n",
    "Однако использование такого способа возможно только тогда, когда имя столбца указано без пробелов.\n",
    "\n",
    "Другой вариант — обратиться к DataFrame по индексу и указать имя столбца:\n",
    "countries_df['population']\n",
    "\n",
    "Примечание. Обратите внимание, что, как и ожидалось, при обращении к столбцу DataFrame мы получаем объект Series с именем, соответствующим имени столбца. Удостовериться в этом можно с помощью функции type():\n",
    "\n",
    "type(countries_df.population)\n",
    "# pandas.core.series.Series\n",
    "Для того чтобы получить доступ к ячейкам таблицы, используются уже знакомые нам loc и iloc.\n",
    "\n",
    "При этом, в соответствии с механизмом работы axis, при обращении к DataFrame по индексам с помощью loc (iloc) первым индексом указывается индекс (порядковый номер), соответствующий строкам, а вторым — имя (порядковый номер) столбца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАПИСЬ В CSV-ФАЙЛ\n",
    "\n",
    "Предположим, что мы захотели сохранить созданный нами ранее DataFrame. Самым простым и распространённым источником табличных данных является формат csv (comma-separated values). В данном формате ячейки таблицы обозначаются некоторым разделителем, чаще всего запятой либо точкой с запятой.\n",
    "\n",
    "Экспорт данных в формат csv осуществляется с помощью метода DataFrame to_csv().\n",
    "\n",
    "Основные параметры метода DataFrame to_csv()\n",
    "\n",
    "path_or_buf — путь до файла, в который будет записан DataFrame (например, data/my_data.csv);\n",
    "sep — разделитель данных в выходном файле (по умолчанию ',');\n",
    "decimal — разделитель чисел на целую и дробную части в выходном файле (по умолчанию '.');\n",
    "columns — список столбцов, которые нужно записать в файл (по умолчанию записываются все столбцы);\n",
    "index — параметр, определяющий, требуется ли создавать дополнительный столбец с индексами строк в файле (по умолчанию True).\n",
    "\n",
    "Основные параметры функции read_csv()\n",
    "\n",
    "filepath_or_buffer — путь до файла, который мы читаем;\n",
    "sep — разделитель данных (по умолчанию ',');\n",
    "decimal — разделитель чисел на целую и дробную часть в выходном файле (по умолчанию '.');\n",
    "names — список с названиями столбцов для чтения;\n",
    "skiprows — количество строк в файле, которые нужно пропустить (например, файл может содержать служебную информацию, которая нам не нужна).\n",
    "\n",
    "ЧТЕНИЕ CSV-ФАЙЛА ПО ССЫЛКЕ\n",
    "\n",
    "На самом деле файл с данными не обязательно должен храниться у вас на компьютере. Если он находится в открытом доступе по ссылке (например, на Google Диске или GitHub), его можно прочитать и из интернета — для этого достаточно в функции read_csv() вместо пути до файла указать ссылку на файл. Например:\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv')\n",
    "display(data)\n",
    "→ Данные, прочитанные выше, ещё понадобятся нам в этом модуле, а пока предлагаем ознакомиться ещё с несколькими методами.\n",
    "\n",
    "ЗАПИСЬ И ЧТЕНИЕ В ДРУГИХ ФОРМАТАХ\n",
    "\n",
    "Как уже говорилось ранее, Pandas способен работать со многими распространёнными форматами данных.\n",
    "\n",
    "Методы для записи таблиц в файлы отличных от csv форматов:\n",
    "\n",
    "to_excel() — запись DataFrame в формат Excel-таблицы (.xlsx);\n",
    "to_json() — запись DataFrame в формат JSON (.json);\n",
    "to_xml() — запись DataFrame в формат XML-документа (.xml);\n",
    "to_sql() — запись DataFrame в базу данных SQL (для реализации этого метода необходимо установить соединение с базой данных).\n",
    "Методы для чтения таблиц из файлов в отличных от csv форматах:\n",
    "\n",
    "read_excel() — чтение из формата Excel-таблицы (.xlsx) в DataFrame;\n",
    "read_json() — чтение из формата JSON (.json) в DataFrame;\n",
    "read_xml() — чтение из формата XML-документа (.xml) в DataFrame;\n",
    "read_sql() — чтение из базы данных SQL в DataFrame (также необходимо установить соединение с базой данных).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('C:/Users/ilyad/IDE/study/python_10_theory/melb_data.csv', sep=',')\n",
    "round(melb_data.loc[3521, 'Landsize'] / melb_data.loc[1690, 'Landsize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД ПЕРВЫХ И ПОСЛЕДНИХ СТРОК\n",
    "\n",
    "→ Часто бывает такое, что вывести на экран все строки таблицы является ресурсозатратной операцией, а иногда и вовсе не представляется возможным. В большинстве случаев для того, чтобы понять структуру DataFrame и удостовериться, что таблица подгрузилась верно, достаточно вывести несколько первых или последних строк.\n",
    "Для этого у DataFrame есть методы head() и tail(), которые возвращают n первых и n последних строк таблицы соответственно (по умолчанию n = 5).\n",
    "\n",
    "РАЗМЕРНОСТЬ ТАБЛИЦЫ\n",
    "\n",
    "Далее хотелось бы узнать размер таблицы — количество строк и количество столбцов. Это можно сделать с помощью атрибута shape, который возвращает кортеж с количеством строк и столбцов:\n",
    " melb_data.shape\n",
    "\n",
    " ПОЛУЧЕНИЕ ИНФОРМАЦИИ О СТОЛБЦАХ\n",
    "\n",
    "Для того чтобы получить более детальную информацию о столбцах таблицы, можно использовать метод DataFrame info():\n",
    "melb_data.info()\n",
    "Данный метод выводит:\n",
    "информацию об индексах;\n",
    "информацию об общем количестве столбцов;\n",
    "таблицу, в которой содержится информация об именах столбцов (Column), количестве непустых значений (Non-Null Count) в каждом столбце и типе данных столбца (Dtype), количестве столбцов, в которых используется определённый тип данных;\n",
    "количество оперативной памяти в мегабайтах, которое тратится на хранение данных.\n",
    "\n",
    "ИЗМЕНЕНИЕ ТИПА ДАННЫХ В СТОЛБЦЕ\n",
    "\n",
    "→ Если присмотреться внимательнее к выводу метода info(), а конкретнее — к типам данных столбцов, становится понятно, что некоторые признаки кодируются не совсем корректными типами данных. \n",
    "Например, данные в столбцах, которые отражают количество, должны, по идее, выражаться целым числом (Car, Bedroom, Bathroom и Propertyсount), однако кодируются float64 — числом с плавающей запятой размером 64 бита.\n",
    "Наконец, данные в столбце с годом постройки (YearBuilt) также представлены в формате чисел с плавающей точкой.\n",
    "Чтобы исправить это, можно воспользоваться методом astype(), который позволяет преобразовать тип данных столбца:\n",
    "melb_data['Car'] = melb_data['Car'].astype('int64')\n",
    "melb_data['Bedroom'] = melb_data['Bedroom'].astype('int64')\n",
    "melb_data['Bathroom'] = melb_data['Bathroom'].astype('int64')\n",
    "melb_data['Propertycount'] = melb_data['Propertycount'].astype('int64')\n",
    "melb_data['YearBuilt'] = melb_data['YearBuilt'].astype('int64')\n",
    "melb_data.info()\n",
    "\n",
    "ПОЛУЧЕНИЕ ОПИСАТЕЛЬНОЙ СТАТИСТИКИ\n",
    "\n",
    "→ Часто при работе с таблицей нужно быстро посмотреть на основные статистические свойства её столбцов. Для этого можно воспользоваться методом DataFrame describe().\n",
    "\n",
    "→ На самом деле метод describe() можно применять не только к числовым признакам. С помощью параметра include можно указать тип данных, для которого нужно вывести описательную информацию.\n",
    "Например, для типа данных object метод describe() возвращает DataFrame, в котором указаны:\n",
    "количество непустых строк (count);\n",
    "количество уникальных значений (unique);\n",
    "самое частое значение — мода —  (top);\n",
    "частота — объём использования — этого значения (freq) для каждого столбца типа object исходной таблицы.\n",
    "melb_data.describe(include=['object'])\n",
    "\n",
    "ПОЛУЧЕНИЕ ЧАСТОТЫ УНИКАЛЬНЫХ ЗНАЧЕНИЙ В СТОЛБЦЕ\n",
    "\n",
    "→ Для того чтобы определить, сколько раз в столбце повторяется каждый из вариантов значений (т.е. найти частоту для каждого уникального знания), используется метод value_counts().\n",
    "Данный метод возвращает объект Series, в котором в качестве индексов выступают уникальные категории столбца, а значениями — соответствующая им частота.\n",
    "Рассмотрим работу value_counts() на примере столбца с названиями районов:\n",
    "melb_data['Regionname'].value_counts()\n",
    "Чтобы сделать вывод более интерпретируемым и понятным, можно воспользоваться параметром normalize. При установке значения этого параметра на True результат будет представляться в виде доли (относительной частоты):\n",
    "melb_data['Regionname'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   index          13580 non-null  int64  \n",
      " 1   Suburb         13580 non-null  object \n",
      " 2   Address        13580 non-null  object \n",
      " 3   Rooms          13580 non-null  int64  \n",
      " 4   Type           13580 non-null  object \n",
      " 5   Price          13580 non-null  float64\n",
      " 6   Method         13580 non-null  object \n",
      " 7   SellerG        13580 non-null  object \n",
      " 8   Date           13580 non-null  object \n",
      " 9   Distance       13580 non-null  float64\n",
      " 10  Postcode       13580 non-null  int64  \n",
      " 11  Bedroom        13580 non-null  float64\n",
      " 12  Bathroom       13580 non-null  float64\n",
      " 13  Car            13580 non-null  float64\n",
      " 14  Landsize       13580 non-null  float64\n",
      " 15  BuildingArea   13580 non-null  float64\n",
      " 16  YearBuilt      13580 non-null  float64\n",
      " 17  CouncilArea    12211 non-null  object \n",
      " 18  Lattitude      13580 non-null  float64\n",
      " 19  Longtitude     13580 non-null  float64\n",
      " 20  Regionname     13580 non-null  object \n",
      " 21  Propertycount  13580 non-null  float64\n",
      " 22  Coordinates    13580 non-null  object \n",
      "dtypes: float64(11), int64(3), object(9)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('C:/Users/ilyad/IDE/study/python_10_theory/melb_data.csv', sep=',')\n",
    "melb_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
